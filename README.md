# Person Detection with YOLOv8

Проект по детекции людей на видео с помощью модели YOLOv8.  
В качестве входных данных используется видео `crowd.mp4` — прогулочная улица с туристами.  
Выход — видеоролик с фигурами, обведёнными рамками и подписями `person <уверенность>`.

## Структура проекта

```bash
crowd_detection_project/
├── main.py               # Точка входа — запускает инференс
├── inference.py          # Логика обработки видео и отрисовки
├── requirements.txt      # Зависимости проекта
├── README.md             # Описание проекта
├── training.ipynb        # Jupyter Notebook: обучение модели
├── weights/
│   └── yolov8n_final.pt  # Обученная модель YOLOv8
├── data/
│   └── crowd.mp4         # Исходное видео
├── output/
│   └── crowd_annotated.mp4  # Результат инференса
```

## Установка

1. Склонируйте репозиторий или скачайте `.zip` с проектом
2. Установите зависимости:

```bash
pip install -r requirements.txt
```

Требуется Python 3.9 — 3.11

## Запуск
Выполните команду в терминале из корневой папки проекта:

```bash
python main.py --model weights/yolov8n_final.pt --source data/crowd.mp4 --output output/crowd_annotated.mp4
```

Результат:
- В папке output/ появится файл crowd_annotated.mp4
- На видео будут показаны рамки вокруг людей и confidence для каждого объекта

## Описание модели

- Использована модель **YOLOv8n** от Ultralytics
- Два этапа дообучения:
  1. Первый этап — на open-source датасете из [RoboFlow](https://universe.roboflow.com/shou-eejwn/person-detection-oahvf)
  2. Второй этап — на [размеченных вручную кадрах](https://universe.roboflow.com/workspace-ggk1p/human-detection-cm0ky), извлеченных из `crowd.mp4`
- Обучение производилось в Google Colab  
- Все шаги обучения, загрузки и подготовки датасета описаны в `training.ipynb`
- Полученные веса `yolov8n_final.pt` применяются к полному видео

## Технологии
- Python 3.10
- OpenCV
- Ultralytics YOLOv8

## Выводы по результатам работы программы

Модель показала уверенные результаты на тестовом видео `crowd.mp4`.  
Обнаружение людей оказалось наиболее точным в тех частях сцены, где:
- Люди находятся ближе к камере, не перекрывают друг друга

Однако в части, где:
- Присутствует **толпа на заднем плане**
- Люди **перекрывают** друг друга
- Камера **плавно движется**, создавая размытое или меняющееся изображение

— наблюдаются пропуски (false negatives) и **нестабильность рамок** (они "прыгают" между объектами, либо теряются при движении).

Тем не менее, если **поставить видео на паузу**, можно заметить, что модель в целом уверенно находит отдельные фигуры в толпе — особенно при хорошей освещенности и если человек достаточно крупный. При этом рамки не перекрывают изображение и удобно читаются.

## Шаги по дальнейшему улучшению качества

Чтобы повысить точность и устойчивость модели в сложных условиях (толпа, движение), можно предпринять следующие действия:
1. **Использовать трекинг (multi-object tracking):**
   - Внедрение алгоритмов отслеживания (например, `DeepSort`, `ByteTrack`, `StrongSORT`) позволит «сопровождать» каждую рамку между кадрами и избежать скачков
   - Это поможет сохранить идентичность объектов в толпе

2. **Увеличить разнообразие данных для дообучения:**
   - Добавить больше размеченных кадров именно из плотных участков толпы

3. **Взять более мощную модель YOLOv8 (например, `yolov8m` или `yolov8l`)**
   - Текущее решение основано на `YOLOv8n` (наименьшая модель)
   - Более крупные модели улучшают точность за счёт большего количества параметров (но требуют больше ресурсов)

4. **Применить аугментации при дообучении:**
   - Aугментации типа `RandomBlur`, `MotionBlur`, `Cutout`, `Mosaic`, `MixUp`
   - Это помогает симулировать условия движения камеры и плотной толпы